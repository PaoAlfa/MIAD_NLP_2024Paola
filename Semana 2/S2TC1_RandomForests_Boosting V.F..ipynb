{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de modelos Bagging, Random Forest y XGBoost\n",
    "\n",
    "En este taller podrán poner en práctica sus conocimientos sobre la construcción e implementación de modelos de Bagging, Random Forest y XGBoost. El taller está constituido por 8 puntos, en los cuales deberan seguir las intrucciones de cada numeral para su desarrollo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos predicción precio de automóviles\n",
    "\n",
    "En este taller se usará el conjunto de datos de Car Listings de Kaggle donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>M_Camry</th>\n",
       "      <th>M_Camry4dr</th>\n",
       "      <th>M_CamryBase</th>\n",
       "      <th>M_CamryL</th>\n",
       "      <th>M_CamryLE</th>\n",
       "      <th>M_CamrySE</th>\n",
       "      <th>M_CamryXLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21995</td>\n",
       "      <td>2014</td>\n",
       "      <td>6480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13995</td>\n",
       "      <td>2014</td>\n",
       "      <td>39972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>17941</td>\n",
       "      <td>2016</td>\n",
       "      <td>18989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>12493</td>\n",
       "      <td>2014</td>\n",
       "      <td>51330</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>7994</td>\n",
       "      <td>2007</td>\n",
       "      <td>116065</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Year  Mileage  M_Camry  M_Camry4dr  M_CamryBase  M_CamryL  \\\n",
       "7    21995  2014     6480        0           0            0         1   \n",
       "11   13995  2014    39972        0           0            0         0   \n",
       "167  17941  2016    18989        0           0            0         0   \n",
       "225  12493  2014    51330        0           0            0         1   \n",
       "270   7994  2007   116065        0           1            0         0   \n",
       "\n",
       "     M_CamryLE  M_CamrySE  M_CamryXLE  \n",
       "7            0          0           0  \n",
       "11           1          0           0  \n",
       "167          0          1           0  \n",
       "225          0          0           0  \n",
       "270          0          0           0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Lectura de la información de archivo .csv\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/datasets/dataTrain_carListings.zip')\n",
    "\n",
    "# Preprocesamiento de datos para el taller\n",
    "data = data.loc[data['Model'].str.contains('Camry')].drop(['Make', 'State'], axis=1)\n",
    "data = data.join(pd.get_dummies(data['Model'], prefix='M'))\n",
    "data = data.drop(['Model'], axis=1)\n",
    "\n",
    "# Visualización dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de variables predictoras (X) y variable de interés (y)\n",
    "y = data['Price']\n",
    "X = data.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación de datos en set de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Árbol de decisión manual\n",
    "\n",
    "En la celda 1 creen un árbol de decisión **manualmente**  que considere los set de entrenamiento y test definidos anteriormente y presenten el RMSE y MAE del modelo en el set de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_depth = None\n",
    "num_pct = 10\n",
    "max_features = None\n",
    "min_gain=0.001\n",
    "# estos son los parámetros y criterios de parada\n",
    "\n",
    "#gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)\n",
    "\n",
    "\n",
    "    #gini_imputiry según la materia:\n",
    "    \n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_\n",
    "\n",
    "#best_split para mejor bofurcación y variable\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split\n",
    "\n",
    "#tree_grow para crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    #1 observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    #Mejor split\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)\n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "\n",
    "    \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    #División o partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    #en cada partición  \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)  \n",
    "    return tree\n",
    "\n",
    "#tree_predict\n",
    "def tree_predict(X, tree, proba=False):\n",
    "    \n",
    "    predicted = np.ones(X.shape[0])\n",
    "\n",
    "    # Revisar si es el nodo final\n",
    "    if tree['split'] == -1:\n",
    "        if not proba:\n",
    "            predicted = predicted * tree['y_pred']\n",
    "        else:\n",
    "            predicted = predicted * tree['y_prob']\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        j, split = tree['split']\n",
    "        filter_l = (X.iloc[:, j] < split)\n",
    "        X_l = X.loc[filter_l]\n",
    "        X_r = X.loc[~filter_l]\n",
    "\n",
    "        if X_l.shape[0] == 0:  # Si el nodo izquierdo está vacio solo continua con el derecho \n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "        elif X_r.shape[0] == 0:  #  Si el nodo derecho está vacio solo continua con el izquierdo\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "        else:\n",
    "            predicted[filter_l] = tree_predict(X_l, tree['sl'], proba)\n",
    "            predicted[~filter_l] = tree_predict(X_r, tree['sr'], proba)\n",
    "\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_tree = tree_grow(X_train, y_train, level=0, min_gain=0.001, max_depth=None, num_pct=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree_predict(X_test, man_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño del árbol de decisión manual:\n",
      "MSE: 13053199.737009238\n",
      "MAE: 2054.90\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Calcular las predicciones del árbol de decisión manual\n",
    "y_pred_manual_tree = tree_predict(X_test, man_tree)\n",
    "\n",
    "# Calcular el MSE\n",
    "mse_manual_tree = mean_squared_error(y_test, y_pred_manual_tree)\n",
    "\n",
    "# Calcular el MAE\n",
    "mae_manual_tree = mean_absolute_error(y_test, y_pred_manual_tree)\n",
    "\n",
    "print(\"Desempeño del árbol de decisión manual:\")\n",
    "print(f\"MSE: {mse_manual_tree}\")\n",
    "print(f\"MAE: {mae_manual_tree:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Según el árbol construido vemos que el MSE: 3612.92 y el MAE: 2054.90, esto muestra que tiene un nivel de error importante en slas predicciones sobre el precio de los automóviles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Bagging manual\n",
    "\n",
    "En la celda 2 creen un modelo bagging **manualmente** con 10 árboles de regresión y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño del modelo Bagging:\n",
      "MSE: 3191776.60\n",
      "MAE: 1337.06\n",
      "R2: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Celda 2\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "def build_bagging(X_train, y_train, n_trees = 10, max_depth=None):\n",
    "\n",
    "    trees = []\n",
    "\n",
    "    for i in range(n_trees):\n",
    "        X_sample, y_sample = resample(X_train, y_train) # Muestreo Boostrapt \n",
    "        tree = DecisionTreeRegressor(max_depth=max_depth)\n",
    "        tree.fit(X_sample, y_sample)\n",
    "        trees.append(tree)\n",
    "    \n",
    "    return trees\n",
    "\n",
    "def predict_bagging(trees, X):\n",
    "\n",
    "    predictions = np.array([tree.predict(X) for tree in trees]) # prediciones de cada árbol\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "trees = build_bagging(X_train, y_train)\n",
    "y_pred = predict_bagging(trees, X_test)\n",
    "\n",
    "mse_bagging = mean_squared_error(y_test, y_pred)\n",
    "r2_bagging = r2_score(y_test, y_pred)\n",
    "mae_bagging = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo Bagging:\")\n",
    "print(f\"MSE: {mse_bagging:.2f}\")\n",
    "print(f\"MAE: {mae_bagging:.2f}\")\n",
    "print(f\"R2: {r2_bagging:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el modelo  bagging manualmente y con 10 árboles de regresión tenemos mayor error al obtenido con el árbol manual ya que el MSE es de 3243507.98 y el MAE de 1343.71\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Bagging con librería\n",
    "\n",
    "En la celda 3, con la librería sklearn, entrenen un modelo bagging con 10 árboles de regresión y el parámetro `max_features` igual a `log(n_features)` y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño del modelo bagging_lib:\n",
      "MSE: 7663764.02\n",
      "MAE: 2160.76\n",
      "R2: 0.50\n"
     ]
    }
   ],
   "source": [
    "# Celda 3\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "\n",
    "n_trees = 10\n",
    "max_features = int(np.log(X_train.shape[1]))\n",
    "\n",
    "bagging_model = BaggingRegressor(\n",
    "    base_estimator=DecisionTreeRegressor(),\n",
    "    n_estimators=n_trees,\n",
    "    max_features=max_features,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = bagging_model.predict(X_test)\n",
    "\n",
    "mse_bagging_lib = mean_squared_error(y_test, y_pred)\n",
    "r2_bagging_lib = r2_score(y_test, y_pred)\n",
    "mae_bagging_lib = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo bagging_lib:\")\n",
    "print(f\"MSE: {mse_bagging_lib:.2f}\")\n",
    "print(f\"MAE: {mae_bagging_lib:.2f}\")\n",
    "print(f\"R2: {r2_bagging_lib:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El desempeño del modelo bagging_lib es moderado en la predicción del precio de los automóviles, ya que tiene un MAE de 2160.76, un MSE de 7,663,764.02, y también tiene un error mayor que el árbol de decisión manual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Random forest con librería\n",
    "\n",
    "En la celda 4, usando la librería sklearn entrenen un modelo de Random Forest para regresión  y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desempeño del modelo random_forest:\n",
      "MSE: 3116678.92\n",
      "MAE: 1314.42\n",
      "R2: 0.80\n"
     ]
    }
   ],
   "source": [
    "# Celda 4\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "mse_random_forest = mean_squared_error(y_test, y_pred)\n",
    "r2_random_forest = r2_score(y_test, y_pred)\n",
    "mae_random_forest = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo random_forest:\")\n",
    "print(f\"MSE: {mse_random_forest:.2f}\")\n",
    "print(f\"MAE: {mae_random_forest:.2f}\")\n",
    "print(f\"R2: {r2_random_forest:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo Random Forest presenta un desempeño mejor que los modelos anteriores con:\n",
    "MSE: 3116678.92\n",
    "MAE: 1314.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Calibración de parámetros Random forest\n",
    "\n",
    "En la celda 5, calibren los parámetros max_depth, max_features y n_estimators del modelo de Randon Forest para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Mejores parámetros encontrados: {'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 250}\n",
      "Tiempo de entrenamiento: 38.05 segundos\n",
      "\n",
      "Desempeño del modelo random_forest_cv:\n",
      "MSE: 2447939.89\n",
      "MAE: 1147.02\n",
      "R2: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Celda 5\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, None], \n",
    "    'max_features': ['auto', 'sqrt', 'log2'], \n",
    "    'n_estimators':  [50, 100, 200, 250]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\\n\")\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "mse_random_forest_cv = mean_squared_error(y_test, y_pred)\n",
    "r2_random_forest_cv = r2_score(y_test, y_pred)\n",
    "mae_random_forest_cv = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo random_forest_cv:\")\n",
    "print(f\"MSE: {mse_random_forest_cv:.2f}\")\n",
    "print(f\"MAE: {mae_random_forest_cv:.2f}\")\n",
    "print(f\"R2: {r2_random_forest_cv:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El  modelo random_forest_cv tiene un MSE de 2447939.89 y un MAE de 1147.02, con menor error  en comparación con los modelos anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>max_features</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>2.428256e+06</td>\n",
       "      <td>150345.403393</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>2.419406e+06</td>\n",
       "      <td>146853.412879</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>2.417250e+06</td>\n",
       "      <td>147111.306297</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>2.414295e+06</td>\n",
       "      <td>145687.770977</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>2.385725e+06</td>\n",
       "      <td>156209.181796</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>2.377178e+06</td>\n",
       "      <td>153173.751698</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>2.367313e+06</td>\n",
       "      <td>153606.538913</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>2.363413e+06</td>\n",
       "      <td>153651.935168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>2.385725e+06</td>\n",
       "      <td>156209.181796</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.377178e+06</td>\n",
       "      <td>153173.751698</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>2.367313e+06</td>\n",
       "      <td>153606.538913</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>250</td>\n",
       "      <td>2.363413e+06</td>\n",
       "      <td>153651.935168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>2.968002e+06</td>\n",
       "      <td>181182.001841</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>2.959658e+06</td>\n",
       "      <td>185299.302695</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>2.953398e+06</td>\n",
       "      <td>183133.427180</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>2.946925e+06</td>\n",
       "      <td>181581.186572</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>3.047361e+06</td>\n",
       "      <td>193508.180785</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>3.037220e+06</td>\n",
       "      <td>197274.940231</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>3.030285e+06</td>\n",
       "      <td>192907.257708</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>3.025956e+06</td>\n",
       "      <td>193524.994424</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>3.047361e+06</td>\n",
       "      <td>193508.180785</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>3.037220e+06</td>\n",
       "      <td>197274.940231</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>3.030285e+06</td>\n",
       "      <td>192907.257708</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>250</td>\n",
       "      <td>3.025956e+06</td>\n",
       "      <td>193524.994424</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>30.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>3.031254e+06</td>\n",
       "      <td>183736.354062</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>30.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>3.019506e+06</td>\n",
       "      <td>187924.935559</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>30.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>3.012838e+06</td>\n",
       "      <td>188382.762862</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>30.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>3.007270e+06</td>\n",
       "      <td>187639.370351</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>3.117362e+06</td>\n",
       "      <td>200988.600059</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>3.114348e+06</td>\n",
       "      <td>199757.867495</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>3.104714e+06</td>\n",
       "      <td>200352.928181</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30.0</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>3.101411e+06</td>\n",
       "      <td>199097.870117</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>30.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>3.117362e+06</td>\n",
       "      <td>200988.600059</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>30.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>3.114348e+06</td>\n",
       "      <td>199757.867495</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>30.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>3.104714e+06</td>\n",
       "      <td>200352.928181</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>30.0</td>\n",
       "      <td>log2</td>\n",
       "      <td>250</td>\n",
       "      <td>3.101411e+06</td>\n",
       "      <td>199097.870117</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>3.034693e+06</td>\n",
       "      <td>183569.778909</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>3.021917e+06</td>\n",
       "      <td>188149.718544</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>200</td>\n",
       "      <td>3.016054e+06</td>\n",
       "      <td>188650.661551</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>auto</td>\n",
       "      <td>250</td>\n",
       "      <td>3.010539e+06</td>\n",
       "      <td>187871.620615</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>50</td>\n",
       "      <td>3.117987e+06</td>\n",
       "      <td>205650.357019</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>3.114806e+06</td>\n",
       "      <td>203309.436171</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>200</td>\n",
       "      <td>3.105140e+06</td>\n",
       "      <td>202964.314816</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NaN</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>250</td>\n",
       "      <td>3.101287e+06</td>\n",
       "      <td>201990.878306</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>50</td>\n",
       "      <td>3.117987e+06</td>\n",
       "      <td>205650.357019</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>3.114806e+06</td>\n",
       "      <td>203309.436171</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>200</td>\n",
       "      <td>3.105140e+06</td>\n",
       "      <td>202964.314816</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>NaN</td>\n",
       "      <td>log2</td>\n",
       "      <td>250</td>\n",
       "      <td>3.101287e+06</td>\n",
       "      <td>201990.878306</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth max_features  n_estimators  mean_test_score  std_test_score  \\\n",
       "0        10.0         auto            50     2.428256e+06   150345.403393   \n",
       "1        10.0         auto           100     2.419406e+06   146853.412879   \n",
       "2        10.0         auto           200     2.417250e+06   147111.306297   \n",
       "3        10.0         auto           250     2.414295e+06   145687.770977   \n",
       "4        10.0         sqrt            50     2.385725e+06   156209.181796   \n",
       "5        10.0         sqrt           100     2.377178e+06   153173.751698   \n",
       "6        10.0         sqrt           200     2.367313e+06   153606.538913   \n",
       "7        10.0         sqrt           250     2.363413e+06   153651.935168   \n",
       "8        10.0         log2            50     2.385725e+06   156209.181796   \n",
       "9        10.0         log2           100     2.377178e+06   153173.751698   \n",
       "10       10.0         log2           200     2.367313e+06   153606.538913   \n",
       "11       10.0         log2           250     2.363413e+06   153651.935168   \n",
       "12       20.0         auto            50     2.968002e+06   181182.001841   \n",
       "13       20.0         auto           100     2.959658e+06   185299.302695   \n",
       "14       20.0         auto           200     2.953398e+06   183133.427180   \n",
       "15       20.0         auto           250     2.946925e+06   181581.186572   \n",
       "16       20.0         sqrt            50     3.047361e+06   193508.180785   \n",
       "17       20.0         sqrt           100     3.037220e+06   197274.940231   \n",
       "18       20.0         sqrt           200     3.030285e+06   192907.257708   \n",
       "19       20.0         sqrt           250     3.025956e+06   193524.994424   \n",
       "20       20.0         log2            50     3.047361e+06   193508.180785   \n",
       "21       20.0         log2           100     3.037220e+06   197274.940231   \n",
       "22       20.0         log2           200     3.030285e+06   192907.257708   \n",
       "23       20.0         log2           250     3.025956e+06   193524.994424   \n",
       "24       30.0         auto            50     3.031254e+06   183736.354062   \n",
       "25       30.0         auto           100     3.019506e+06   187924.935559   \n",
       "26       30.0         auto           200     3.012838e+06   188382.762862   \n",
       "27       30.0         auto           250     3.007270e+06   187639.370351   \n",
       "28       30.0         sqrt            50     3.117362e+06   200988.600059   \n",
       "29       30.0         sqrt           100     3.114348e+06   199757.867495   \n",
       "30       30.0         sqrt           200     3.104714e+06   200352.928181   \n",
       "31       30.0         sqrt           250     3.101411e+06   199097.870117   \n",
       "32       30.0         log2            50     3.117362e+06   200988.600059   \n",
       "33       30.0         log2           100     3.114348e+06   199757.867495   \n",
       "34       30.0         log2           200     3.104714e+06   200352.928181   \n",
       "35       30.0         log2           250     3.101411e+06   199097.870117   \n",
       "36        NaN         auto            50     3.034693e+06   183569.778909   \n",
       "37        NaN         auto           100     3.021917e+06   188149.718544   \n",
       "38        NaN         auto           200     3.016054e+06   188650.661551   \n",
       "39        NaN         auto           250     3.010539e+06   187871.620615   \n",
       "40        NaN         sqrt            50     3.117987e+06   205650.357019   \n",
       "41        NaN         sqrt           100     3.114806e+06   203309.436171   \n",
       "42        NaN         sqrt           200     3.105140e+06   202964.314816   \n",
       "43        NaN         sqrt           250     3.101287e+06   201990.878306   \n",
       "44        NaN         log2            50     3.117987e+06   205650.357019   \n",
       "45        NaN         log2           100     3.114806e+06   203309.436171   \n",
       "46        NaN         log2           200     3.105140e+06   202964.314816   \n",
       "47        NaN         log2           250     3.101287e+06   201990.878306   \n",
       "\n",
       "    rank_test_score  \n",
       "0                12  \n",
       "1                11  \n",
       "2                10  \n",
       "3                 9  \n",
       "4                 7  \n",
       "5                 5  \n",
       "6                 3  \n",
       "7                 1  \n",
       "8                 7  \n",
       "9                 5  \n",
       "10                3  \n",
       "11                1  \n",
       "12               16  \n",
       "13               15  \n",
       "14               14  \n",
       "15               13  \n",
       "16               31  \n",
       "17               29  \n",
       "18               25  \n",
       "19               23  \n",
       "20               31  \n",
       "21               29  \n",
       "22               25  \n",
       "23               23  \n",
       "24               27  \n",
       "25               21  \n",
       "26               19  \n",
       "27               17  \n",
       "28               45  \n",
       "29               41  \n",
       "30               37  \n",
       "31               35  \n",
       "32               45  \n",
       "33               41  \n",
       "34               37  \n",
       "35               35  \n",
       "36               28  \n",
       "37               22  \n",
       "38               20  \n",
       "39               18  \n",
       "40               47  \n",
       "41               43  \n",
       "42               39  \n",
       "43               33  \n",
       "44               47  \n",
       "45               43  \n",
       "46               39  \n",
       "47               33  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_grid_search(grid_search):\n",
    "    results = pd.DataFrame(grid_search.cv_results_)\n",
    "    results['mean_test_score'] = -results['mean_test_score']  # Convertir a MSE positivo\n",
    "\n",
    "    # Organizar resultados para visualizar el efecto de cada parámetro\n",
    "    params = pd.DataFrame(results['params'].tolist())\n",
    "    results = pd.concat([params, results[['mean_test_score', 'std_test_score', 'rank_test_score']]], axis=1)\n",
    "    return results\n",
    "\n",
    "# Obtener y analizar los resultados del GridSearchCV\n",
    "results = analyze_grid_search(grid_search)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - XGBoost con librería\n",
    "\n",
    "En la celda 6 implementen un modelo XGBoost de regresión con la librería sklearn y comenten sobre el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.0.3-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 817 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/paolaalfaro/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/paolaalfaro/opt/anaconda3/lib/python3.9/site-packages (from xgboost) (1.21.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Tiempo de entrenamiento: 0.09 segundos\n",
      "\n",
      "Desempeño del modelo xgboost:\n",
      "MSE: 2576781.07\n",
      "MAE: 1185.23\n",
      "R2: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Celda 6\n",
    "!pip install xgboost\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror')\n",
    "start_time = time.time()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\\n\")\n",
    "\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "mse_xgboost = mean_squared_error(y_test, y_pred)\n",
    "r2_xgboost = r2_score(y_test, y_pred)\n",
    "mae_xgboost = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo xgboost:\")\n",
    "print(f\"MSE: {mse_xgboost:.2f}\")\n",
    "print(f\"MAE: {mae_xgboost:.2f}\")\n",
    "print(f\"R2: {r2_xgboost:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo XGBoost tiene un MSE de 2576781.07, un MAE de 1185.23  y el tiempo de entrenamiento es rápido de 0.11 segundos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Calibración de parámetros XGBoost\n",
    "\n",
    "En la celda 7 calibren los parámetros learning rate, gamma y colsample_bytree del modelo XGBoost para regresión, comenten sobre el desempeño del modelo y describan cómo cada parámetro afecta el desempeño del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
      "Tiempo de entrenamiento: 1.26 segundos\n",
      "\n",
      "Mejores parámetros encontrados: {'colsample_bytree': 0.7, 'gamma': 0, 'learning_rate': 0.1}\n",
      "Desempeño del modelo xgboost_cv:\n",
      "MSE: 2391571.59\n",
      "MAE: 1134.03\n",
      "R2: 0.84\n"
     ]
    }
   ],
   "source": [
    "# Celda 7\n",
    "\n",
    "# Definir el modelo base\n",
    "xgb = XGBRegressor(objective='reg:squarederror', )\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 1],  \n",
    "    'gamma': [0, 0.01, 0.1, 0.5],          \n",
    "    'colsample_bytree': [0.3, 0.7, 1.0]  \n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Tiempo de entrenamiento: {training_time:.2f} segundos\\n\")\n",
    "\n",
    "print(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n",
    "best_xgb = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "mse_xgboost_cv = mean_squared_error(y_test, y_pred)\n",
    "r2_xgboost_cv = r2_score(y_test, y_pred)\n",
    "mae_xgboost_cv = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Desempeño del modelo xgboost_cv:\")\n",
    "print(f\"MSE: {mse_xgboost_cv:.2f}\")\n",
    "print(f\"MAE: {mae_xgboost_cv:.2f}\")\n",
    "print(f\"R2: {r2_xgboost_cv:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.880986e+06</td>\n",
       "      <td>205211.688674</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.454102e+06</td>\n",
       "      <td>116768.981549</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.626786e+06</td>\n",
       "      <td>32932.241117</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.880986e+06</td>\n",
       "      <td>205211.688674</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.454102e+06</td>\n",
       "      <td>116768.981549</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.626786e+06</td>\n",
       "      <td>32932.241138</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.880986e+06</td>\n",
       "      <td>205211.688674</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.454102e+06</td>\n",
       "      <td>116768.981549</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.626787e+06</td>\n",
       "      <td>32932.295356</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.880986e+06</td>\n",
       "      <td>205211.688674</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.454102e+06</td>\n",
       "      <td>116768.981549</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.626788e+06</td>\n",
       "      <td>32933.351105</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.514998e+06</td>\n",
       "      <td>124709.470416</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.294655e+06</td>\n",
       "      <td>62841.149333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.019343e+06</td>\n",
       "      <td>58877.288533</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.514998e+06</td>\n",
       "      <td>124709.470416</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.294655e+06</td>\n",
       "      <td>62841.149333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.019343e+06</td>\n",
       "      <td>58877.288533</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.514998e+06</td>\n",
       "      <td>124709.470416</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.294655e+06</td>\n",
       "      <td>62841.149333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.019343e+06</td>\n",
       "      <td>58877.288533</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.514998e+06</td>\n",
       "      <td>124709.470416</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.294655e+06</td>\n",
       "      <td>62841.149333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.019343e+06</td>\n",
       "      <td>58877.642710</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.217051e+06</td>\n",
       "      <td>110768.339187</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.345284e+06</td>\n",
       "      <td>51110.302240</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.255588e+06</td>\n",
       "      <td>48707.200608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.217051e+06</td>\n",
       "      <td>110768.339187</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.345284e+06</td>\n",
       "      <td>51110.302240</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.255588e+06</td>\n",
       "      <td>48707.200608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.217051e+06</td>\n",
       "      <td>110768.339187</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.345284e+06</td>\n",
       "      <td>51110.302240</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.255588e+06</td>\n",
       "      <td>48707.200608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>4.217051e+06</td>\n",
       "      <td>110768.339187</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.345284e+06</td>\n",
       "      <td>51110.302240</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.255588e+06</td>\n",
       "      <td>48707.200608</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree  gamma  learning_rate  mean_test_score  std_test_score  \\\n",
       "0                0.3   0.00           0.01     7.880986e+06   205211.688674   \n",
       "1                0.3   0.00           0.10     2.454102e+06   116768.981549   \n",
       "2                0.3   0.00           1.00     2.626786e+06    32932.241117   \n",
       "3                0.3   0.01           0.01     7.880986e+06   205211.688674   \n",
       "4                0.3   0.01           0.10     2.454102e+06   116768.981549   \n",
       "5                0.3   0.01           1.00     2.626786e+06    32932.241138   \n",
       "6                0.3   0.10           0.01     7.880986e+06   205211.688674   \n",
       "7                0.3   0.10           0.10     2.454102e+06   116768.981549   \n",
       "8                0.3   0.10           1.00     2.626787e+06    32932.295356   \n",
       "9                0.3   0.50           0.01     7.880986e+06   205211.688674   \n",
       "10               0.3   0.50           0.10     2.454102e+06   116768.981549   \n",
       "11               0.3   0.50           1.00     2.626788e+06    32933.351105   \n",
       "12               0.7   0.00           0.01     4.514998e+06   124709.470416   \n",
       "13               0.7   0.00           0.10     2.294655e+06    62841.149333   \n",
       "14               0.7   0.00           1.00     3.019343e+06    58877.288533   \n",
       "15               0.7   0.01           0.01     4.514998e+06   124709.470416   \n",
       "16               0.7   0.01           0.10     2.294655e+06    62841.149333   \n",
       "17               0.7   0.01           1.00     3.019343e+06    58877.288533   \n",
       "18               0.7   0.10           0.01     4.514998e+06   124709.470416   \n",
       "19               0.7   0.10           0.10     2.294655e+06    62841.149333   \n",
       "20               0.7   0.10           1.00     3.019343e+06    58877.288533   \n",
       "21               0.7   0.50           0.01     4.514998e+06   124709.470416   \n",
       "22               0.7   0.50           0.10     2.294655e+06    62841.149333   \n",
       "23               0.7   0.50           1.00     3.019343e+06    58877.642710   \n",
       "24               1.0   0.00           0.01     4.217051e+06   110768.339187   \n",
       "25               1.0   0.00           0.10     2.345284e+06    51110.302240   \n",
       "26               1.0   0.00           1.00     3.255588e+06    48707.200608   \n",
       "27               1.0   0.01           0.01     4.217051e+06   110768.339187   \n",
       "28               1.0   0.01           0.10     2.345284e+06    51110.302240   \n",
       "29               1.0   0.01           1.00     3.255588e+06    48707.200608   \n",
       "30               1.0   0.10           0.01     4.217051e+06   110768.339187   \n",
       "31               1.0   0.10           0.10     2.345284e+06    51110.302240   \n",
       "32               1.0   0.10           1.00     3.255588e+06    48707.200608   \n",
       "33               1.0   0.50           0.01     4.217051e+06   110768.339187   \n",
       "34               1.0   0.50           0.10     2.345284e+06    51110.302240   \n",
       "35               1.0   0.50           1.00     3.255588e+06    48707.200608   \n",
       "\n",
       "    rank_test_score  \n",
       "0                33  \n",
       "1                 9  \n",
       "2                13  \n",
       "3                33  \n",
       "4                 9  \n",
       "5                14  \n",
       "6                33  \n",
       "7                 9  \n",
       "8                15  \n",
       "9                33  \n",
       "10                9  \n",
       "11               16  \n",
       "12               29  \n",
       "13                1  \n",
       "14               17  \n",
       "15               29  \n",
       "16                1  \n",
       "17               17  \n",
       "18               29  \n",
       "19                1  \n",
       "20               17  \n",
       "21               29  \n",
       "22                1  \n",
       "23               20  \n",
       "24               25  \n",
       "25                5  \n",
       "26               21  \n",
       "27               25  \n",
       "28                5  \n",
       "29               21  \n",
       "30               25  \n",
       "31                5  \n",
       "32               21  \n",
       "33               25  \n",
       "34                5  \n",
       "35               21  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = analyze_grid_search(grid_search)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La calibración de los parámetros del modelo XGBoost muestran combinaciones que afectan el rendimiento tales como learning_rate afectando la velocidad y generalización, \n",
    "gamma que maneja la pérdida mínima para dividir nodos \n",
    "colsample_bytree reduciendo el sobreajuste al seleccionar características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Comparación y análisis de resultados\n",
    "En la celda 8 comparen los resultados obtenidos de los diferentes modelos (random forest y XGBoost) y comenten las ventajas del mejor modelo y las desventajas del modelo con el menor desempeño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor modelo es XGBoost CV con un MSE de 2391571.59\n",
      "[CV] END ...max_depth=10, max_features=auto, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...max_depth=20, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=200; total time=   2.2s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=100; total time=   1.2s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=30, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...max_depth=30, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END .max_depth=None, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=250; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=250; total time=   1.5s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.5, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...max_depth=10, max_features=auto, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=250; total time=   0.9s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=250; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=250; total time=   2.6s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=250; total time=   2.8s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=250; total time=   1.8s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=250; total time=   1.8s\n",
      "[CV] END .max_depth=None, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=250; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=250; total time=   1.3s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=0.7, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...max_depth=10, max_features=auto, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=250; total time=   1.0s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=200; total time=   0.7s\n",
      "[CV] END ...max_depth=20, max_features=auto, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=100; total time=   1.3s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END ...max_depth=30, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=250; total time=   1.8s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END .max_depth=None, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=250; total time=   1.6s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ...max_depth=10, max_features=auto, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=250; total time=   0.9s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=250; total time=   1.0s\n",
      "[CV] END ...max_depth=20, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=30, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=100; total time=   1.1s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=200; total time=   2.2s\n",
      "[CV] END ...max_depth=30, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...max_depth=30, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=30, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=250; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END .....colsample_bytree=0.3, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.1, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=250; total time=   1.0s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=250; total time=   1.0s\n",
      "[CV] END ...max_depth=20, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=250; total time=   2.6s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=100; total time=   1.2s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=1.0, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=1.0, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=1.0, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...max_depth=10, max_features=auto, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=250; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=200; total time=   2.2s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=30, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...max_depth=30, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=100; total time=   1.3s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=250; total time=   1.8s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=250; total time=   1.8s\n",
      "[CV] END .max_depth=None, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=250; total time=   2.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=250; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=0.3, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=0.7, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=0.7, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...max_depth=10, max_features=log2, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=250; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=200; total time=   2.2s\n",
      "[CV] END ...max_depth=20, max_features=sqrt, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...max_depth=30, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END ...max_depth=30, max_features=auto, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=200; total time=   2.3s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=250; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=250; total time=   1.2s\n",
      "[CV] END .....colsample_bytree=0.3, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.3, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.3, gamma=0.5, learning_rate=0.1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0.01, learning_rate=1; total time=   0.1s\n",
      "[CV] END .....colsample_bytree=1.0, gamma=0, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=1.0, gamma=0.5, learning_rate=1; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=10, max_features=auto, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=10, max_features=sqrt, n_estimators=50; total time=   0.2s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=sqrt, n_estimators=250; total time=   0.9s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=100; total time=   0.4s\n",
      "[CV] END ..max_depth=10, max_features=log2, n_estimators=200; total time=   0.8s\n",
      "[CV] END ...max_depth=20, max_features=auto, n_estimators=50; total time=   0.6s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=100; total time=   1.0s\n",
      "[CV] END ..max_depth=20, max_features=auto, n_estimators=250; total time=   2.7s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=100; total time=   0.6s\n",
      "[CV] END ..max_depth=20, max_features=sqrt, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...max_depth=20, max_features=log2, n_estimators=50; total time=   0.4s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END ..max_depth=20, max_features=log2, n_estimators=250; total time=   1.7s\n",
      "[CV] END ..max_depth=30, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END ...max_depth=30, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END ...max_depth=30, max_features=sqrt, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=100; total time=   0.8s\n",
      "[CV] END ..max_depth=30, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END ...max_depth=30, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END ...max_depth=30, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=100; total time=   0.7s\n",
      "[CV] END ..max_depth=30, max_features=log2, n_estimators=200; total time=   1.5s\n",
      "[CV] END .max_depth=None, max_features=auto, n_estimators=50; total time=   0.5s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=auto, n_estimators=200; total time=   2.1s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END .max_depth=None, max_features=sqrt, n_estimators=50; total time=   0.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=100; total time=   0.7s\n",
      "[CV] END max_depth=None, max_features=sqrt, n_estimators=200; total time=   1.4s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END .max_depth=None, max_features=log2, n_estimators=50; total time=   0.3s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=100; total time=   0.8s\n",
      "[CV] END max_depth=None, max_features=log2, n_estimators=200; total time=   1.3s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.3, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.1, learning_rate=1; total time=   0.0s\n",
      "[CV] END ...colsample_bytree=0.3, gamma=0.1, learning_rate=1; total time=   0.1s\n",
      "[CV] END ..colsample_bytree=0.7, gamma=0, learning_rate=0.01; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=0.7, gamma=0.5, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END ...colsample_bytree=0.7, gamma=0.5, learning_rate=1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.01, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END .colsample_bytree=1.0, gamma=0.1, learning_rate=0.1; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01; total time=   0.1s\n"
     ]
    }
   ],
   "source": [
    "# Celda 8\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mse_scores = {\n",
    "    'Árbol Manual': mse_manual_tree,\n",
    "    'Bagging': mse_bagging,\n",
    "    'Bagging (Library)': mse_bagging_lib,\n",
    "    'Random Forest': mse_random_forest,\n",
    "    'Random Forest CV': mse_random_forest_cv,\n",
    "    'XGBoost': mse_xgboost,\n",
    "    'XGBoost CV': mse_xgboost_cv\n",
    "}\n",
    "\n",
    "models = list(mse_scores.keys())\n",
    "mse_values = list(mse_scores.values())\n",
    "\n",
    "# Crear el gráfico de barras\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(models, mse_values, color='skyblue')\n",
    "plt.xlabel('Modelos')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('Comparación de MSE entre Modelos')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "best_model = min(mse_scores, key=mse_scores.get)\n",
    "best_mse = mse_scores[best_model]\n",
    "\n",
    "print(f\"El mejor modelo es {best_model} con un MSE de {best_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Random Forest con validación cruzada XGBoost CV es el modelo mejor para predecir los precios de los automóviles \n",
    "\n",
    "Su capacidad para reducir el sobreajuste y su mejor rendimiento general lo hacen estar sobre otros modelos, como el Árbol de Decisión Manual. \n",
    "No obstante requiere requiere ajustar algunos parámetros, su implementación es relativamente sencilla y ofrece resultados más precisos y confiables en comparación con modelos más simples.\n",
    "\n",
    "En el caso de las desventajas del modelo con menor desempeño que es el Árbol de Decisión Manual: Muestra un alto error de predicción, además  tiene menor sensibilidad a la calidad de los datos\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
